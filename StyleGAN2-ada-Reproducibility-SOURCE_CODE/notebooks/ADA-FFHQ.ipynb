{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 1.14.0\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import sys\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "dotenv.load_dotenv(override=True)\n",
    "WORK = os.getenv('WORK')\n",
    "sys.path.insert(0, f'{WORK}/ADA_Project')\n",
    "sys.path.insert(0, f'{WORK}/ADA_Project/StyleGAN2-ADA')\n",
    "\n",
    "import DeepFAMS\n",
    "\n",
    "WORK, PROJ_DIR = DeepFAMS.utils.set_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_IMGS_DIR, RESIZED_IMGS_DIR, DATA_CUSTOM_DIR, TRAIN_RUNS_DIR = DeepFAMS.utils.return_dirs(\n",
    "    PROJ_DIR, 'FFHQ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! $WORK/.conda/envs/ada-env/bin/kaggle datasets download -d \\\n",
    "#     arnaud58/flickrfaceshq-dataset-ffhq -p $WORK/ADA_Project/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloaded_file = f'{Path(RAW_IMGS_DIR).parent}/flickrfaceshq-dataset-ffhq.zip'\n",
    "\n",
    "# with zipfile.ZipFile(downloaded_file) as zf:    \n",
    "#     for member in tqdm(zf.infolist(), desc='Extracting'):\n",
    "#         try:\n",
    "#             zf.extract(member, RAW_IMGS_DIR)\n",
    "#         except zipfile.error as e:\n",
    "#             pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52001\n"
     ]
    }
   ],
   "source": [
    "raw_imgs = glob(f'{RAW_IMGS_DIR}/*')\n",
    "print(len(raw_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in tqdm(raw_imgs):\n",
    "#     DeepFAMS.preprocessing.resize_imgs(x, (256, 256), RESIZED_IMGS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw: 52001, Resized: 52001\n"
     ]
    }
   ],
   "source": [
    "print(f'Raw: {len(raw_imgs)}, Resized: {len(glob(f\"{RESIZED_IMGS_DIR}/*\"))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from \"/work/chaselab/malyetama/ADA_Project/datasets/FFHQ_resized\"\n",
      "Creating dataset \"/work/chaselab/malyetama/ADA_Project/datasets/FFHQ_custom_30K\"\n",
      "Added 30000 images.                     \n"
     ]
    }
   ],
   "source": [
    "# DeepFAMS.preprocessing.tf_record_exporter(\n",
    "#     tfrecord_dir=DATA_CUSTOM_DIR, image_dir=RESIZED_IMGS_DIR, shuffle=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 18 19:24:30 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.67       Driver Version: 460.67       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100S-PCI...  On   | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   71C    P0   174W / 250W |   9095MiB / 32510MiB |     85%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100S-PCI...  On   | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   68C    P0   216W / 250W |   9095MiB / 32510MiB |     84%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    222408      C   ...a/envs/ada-env/bin/python     9089MiB |\n",
      "|    1   N/A  N/A    222408      C   ...a/envs/ada-env/bin/python     9089MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "DeepFAMS.utils.execute('nvidia-smi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training options:\n",
      "\n",
      "{\n",
      "\n",
      "  \"G_args\": {\n",
      "\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "\n",
      "    \"fmap_base\": 8192,\n",
      "\n",
      "    \"fmap_max\": 512,\n",
      "\n",
      "    \"mapping_layers\": 2,\n",
      "\n",
      "    \"num_fp16_res\": 4,\n",
      "\n",
      "    \"conv_clamp\": 256\n",
      "\n",
      "  },\n",
      "\n",
      "  \"D_args\": {\n",
      "\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "\n",
      "    \"mbstd_group_size\": 4,\n",
      "\n",
      "    \"fmap_base\": 8192,\n",
      "\n",
      "    \"fmap_max\": 512,\n",
      "\n",
      "    \"num_fp16_res\": 4,\n",
      "\n",
      "    \"conv_clamp\": 256\n",
      "\n",
      "  },\n",
      "\n",
      "  \"G_opt_args\": {\n",
      "\n",
      "    \"beta1\": 0.0,\n",
      "\n",
      "    \"beta2\": 0.99,\n",
      "\n",
      "    \"learning_rate\": 0.0025\n",
      "\n",
      "  },\n",
      "\n",
      "  \"D_opt_args\": {\n",
      "\n",
      "    \"beta1\": 0.0,\n",
      "\n",
      "    \"beta2\": 0.99,\n",
      "\n",
      "    \"learning_rate\": 0.0025\n",
      "\n",
      "  },\n",
      "\n",
      "  \"loss_args\": {\n",
      "\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "\n",
      "    \"r1_gamma\": 0.4096\n",
      "\n",
      "  },\n",
      "\n",
      "  \"augment_args\": {\n",
      "\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "\n",
      "    \"tune_target\": 0.6,\n",
      "\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "\n",
      "    \"apply_args\": {\n",
      "\n",
      "      \"xflip\": 1,\n",
      "\n",
      "      \"rotate90\": 1,\n",
      "\n",
      "      \"xint\": 1,\n",
      "\n",
      "      \"scale\": 1,\n",
      "\n",
      "      \"rotate\": 1,\n",
      "\n",
      "      \"aniso\": 1,\n",
      "\n",
      "      \"xfrac\": 1,\n",
      "\n",
      "      \"brightness\": 1,\n",
      "\n",
      "      \"contrast\": 1,\n",
      "\n",
      "      \"lumaflip\": 1,\n",
      "\n",
      "      \"hue\": 1,\n",
      "\n",
      "      \"saturation\": 1\n",
      "\n",
      "    }\n",
      "\n",
      "  },\n",
      "\n",
      "  \"num_gpus\": 2,\n",
      "\n",
      "  \"image_snapshot_ticks\": 1,\n",
      "\n",
      "  \"network_snapshot_ticks\": 1,\n",
      "\n",
      "  \"train_dataset_args\": {\n",
      "\n",
      "    \"path\": \"/work/chaselab/malyetama/ADA_Project/datasets/FFHQ_custom_30K\",\n",
      "\n",
      "    \"max_label_size\": 0,\n",
      "\n",
      "    \"resolution\": 256,\n",
      "\n",
      "    \"mirror_augment\": false\n",
      "\n",
      "  },\n",
      "\n",
      "  \"metric_arg_list\": [\n",
      "\n",
      "    {\n",
      "\n",
      "      \"name\": \"fid50k_full\",\n",
      "\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "\n",
      "      \"max_reals\": null,\n",
      "\n",
      "      \"num_fakes\": 50000,\n",
      "\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "\n",
      "      \"force_dataset_args\": {\n",
      "\n",
      "        \"shuffle\": false,\n",
      "\n",
      "        \"max_images\": null,\n",
      "\n",
      "        \"repeat\": false,\n",
      "\n",
      "        \"mirror_augment\": false\n",
      "\n",
      "      }\n",
      "\n",
      "    }\n",
      "\n",
      "  ],\n",
      "\n",
      "  \"metric_dataset_args\": {\n",
      "\n",
      "    \"path\": \"/work/chaselab/malyetama/ADA_Project/datasets/FFHQ_custom_30K\",\n",
      "\n",
      "    \"max_label_size\": 0,\n",
      "\n",
      "    \"resolution\": 256,\n",
      "\n",
      "    \"mirror_augment\": false\n",
      "\n",
      "  },\n",
      "\n",
      "  \"total_kimg\": 1,\n",
      "\n",
      "  \"minibatch_size\": 32,\n",
      "\n",
      "  \"minibatch_gpu\": 16,\n",
      "\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "\n",
      "  \"G_smoothing_rampup\": 0.05,\n",
      "\n",
      "  \"run_dir\": \"/work/chaselab/malyetama/ADA_Project/training_runs/FFHQ_training-runs_30K/00000-FFHQ_custom_30K-auto2-kimg1\"\n",
      "\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "Output directory:  /work/chaselab/malyetama/ADA_Project/training_runs/FFHQ_training-runs_30K/00000-FFHQ_custom_30K-auto2-kimg1\n",
      "\n",
      "Training data:     /work/chaselab/malyetama/ADA_Project/datasets/FFHQ_custom_30K\n",
      "\n",
      "Training length:   1 kimg\n",
      "\n",
      "Resolution:        256\n",
      "\n",
      "Number of GPUs:    2\n",
      "\n",
      "\n",
      "\n",
      "Creating output directory...\n",
      "\n",
      "Loading training set...\n",
      "\n",
      "Image shape: [3, 256, 256]\n",
      "\n",
      "Label shape: [0]\n",
      "\n",
      "\n",
      "\n",
      "Constructing networks...\n",
      "\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Loading... Done.\n",
      "\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Loading... Done.\n",
      "\n",
      "\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "\n",
      "---                           ---       ---                 ---             \n",
      "\n",
      "latents_in                    -         (?, 512)            -               \n",
      "\n",
      "labels_in                     -         (?, 0)              -               \n",
      "\n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "\n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "\n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "\n",
      "G_mapping/Broadcast           -         (?, 14, 512)        -               \n",
      "\n",
      "dlatent_avg                   -         (512,)              -               \n",
      "\n",
      "Truncation/Lerp               -         (?, 14, 512)        -               \n",
      "\n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "\n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "\n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "\n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "\n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "\n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "\n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "\n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "\n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "\n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "\n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "\n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "\n",
      "G_synthesis/256x256/Conv0_up  139457    (?, 64, 256, 256)   (3, 3, 128, 64) \n",
      "\n",
      "G_synthesis/256x256/Conv1     69761     (?, 64, 256, 256)   (3, 3, 64, 64)  \n",
      "\n",
      "G_synthesis/256x256/Upsample  -         (?, 3, 256, 256)    -               \n",
      "\n",
      "G_synthesis/256x256/ToRGB     33027     (?, 3, 256, 256)    (1, 1, 64, 3)   \n",
      "\n",
      "---                           ---       ---                 ---             \n",
      "\n",
      "Total                         23191522                                      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "\n",
      "---                  ---       ---                 ---             \n",
      "\n",
      "images_in            -         (?, 3, 256, 256)    -               \n",
      "\n",
      "labels_in            -         (?, 0)              -               \n",
      "\n",
      "256x256/FromRGB      256       (?, 64, 256, 256)   (1, 1, 3, 64)   \n",
      "\n",
      "256x256/Conv0        36928     (?, 64, 256, 256)   (3, 3, 64, 64)  \n",
      "\n",
      "256x256/Conv1_down   73856     (?, 128, 128, 128)  (3, 3, 64, 128) \n",
      "\n",
      "256x256/Skip         8192      (?, 128, 128, 128)  (1, 1, 64, 128) \n",
      "\n",
      "128x128/Conv0        147584    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "\n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "\n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "\n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "\n",
      "---                  ---       ---                 ---             \n",
      "\n",
      "Total                24001089                                      \n",
      "\n",
      "\n",
      "\n",
      "Exporting sample images...\n",
      "\n",
      "Replicating networks across 2 GPUs...\n",
      "\n",
      "Initializing augmentations...\n",
      "\n",
      "Setting up optimizers...\n",
      "\n",
      "Constructing training graph...\n",
      "\n",
      "Finalizing training ops...\n",
      "\n",
      "Initializing metrics...\n",
      "\n",
      "Training for 1 kimg...\n",
      "\n",
      "\n",
      "\n",
      "tick 0     kimg 0.1      time 3m 24s       sec/tick 63.8    sec/kimg 498.56  maintenance 140.5  gpumem 7.1   augment 0.000\n",
      "\n",
      "Evaluating metrics...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating real image statistics for fid50k_full...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DeepFAMS.utils.executePopen(f'''#!/bin/bash\n",
    "module load anaconda\n",
    "module load compiler/gcc/4.7\n",
    "module load cuda\n",
    "$WORK/.conda/envs/ada-env/bin/python $WORK/ADA_Project/StyleGAN2-ada/train.py \\\n",
    "--outdir={TRAIN_RUNS_DIR} \\\n",
    "--gpus=2 \\\n",
    "--data={DATA_CUSTOM_DIR} \\\n",
    "--snap=1 \\\n",
    "--kimg=1''', PROJ_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/chaselab/malyetama/ADA_Project/training_runs/FFHQ_training-runs_30K/00000-FFHQ_custom_30K-auto2-kimg1/network-snapshot-000000.pkl\n"
     ]
    }
   ],
   "source": [
    "for num in range(-1, -10, -1):\n",
    "    files = DeepFAMS.utils.last_snap(num, TRAIN_RUNS_DIR)\n",
    "    if files != []:\n",
    "        break\n",
    "\n",
    "latest_snap = sorted(files)[-1]\n",
    "print(latest_snap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_desc, training_options = DeepFAMS.setup_training_options(\n",
    "    gpus       = 2,\n",
    "    snap       = 30,\n",
    "    data       = DATA_CUSTOM_DIR,\n",
    "    resume     = latest_snap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 0.4096\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.6,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 2,\n",
      "  \"image_snapshot_ticks\": 30,\n",
      "  \"network_snapshot_ticks\": 30,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"/work/chaselab/malyetama/ADA_Project/datasets/FFHQ_custom_30K\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 256,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"/work/chaselab/malyetama/ADA_Project/datasets/FFHQ_custom_30K\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 256,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 25000,\n",
      "  \"minibatch_size\": 32,\n",
      "  \"minibatch_gpu\": 16,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"/work/chaselab/malyetama/ADA_Project/training_runs/FFHQ_training-runs_30K/00000-FFHQ_custom_30K-auto2-kimg1/network-snapshot-000000.pkl\",\n",
      "  \"run_dir\": \"/work/chaselab/malyetama/ADA_Project/training_runs/FFHQ_training-runs_30K/00001-FFHQ_custom_30K-auto2-resumecustom\"\n",
      "}\n",
      "\n",
      "Output directory:  /work/chaselab/malyetama/ADA_Project/training_runs/FFHQ_training-runs_30K/00001-FFHQ_custom_30K-auto2-resumecustom\n",
      "Training data:     /work/chaselab/malyetama/ADA_Project/datasets/FFHQ_custom_30K\n",
      "Training length:   25000 kimg\n",
      "Resolution:        256\n",
      "Number of GPUs:    2\n",
      "\n",
      "Dry run; exiting.\n"
     ]
    }
   ],
   "source": [
    "DeepFAMS.RunTraining(outdir=TRAIN_RUNS_DIR, seed=1000,\n",
    "             dry_run=True, run_desc=run_desc, training_options=training_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "DeepFAMS.RunTraining(outdir=TRAIN_RUNS_DIR, seed=1000,\n",
    "             dry_run=False, run_desc=run_desc, training_options=training_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ada-env)",
   "language": "python",
   "name": "ada-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
