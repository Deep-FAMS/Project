{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 1.14.0\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import zipfile\n",
    "import subprocess\n",
    "import sys\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "dotenv.load_dotenv(override=True)\n",
    "WORK = os.getenv('WORK')\n",
    "sys.path.insert(0, f'{WORK}/ADA_Project')\n",
    "import DeepFAMS\n",
    "\n",
    "WORK, PROJ_DIR = DeepFAMS.utils.set_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_IMGS_DIR, RESIZED_IMGS_DIR, DATA_CUSTOM_DIR, TRAIN_RUNS_DIR = DeepFAMS.utils.return_dirs(\n",
    "    PROJ_DIR, 'AFHQ-DOG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_IMGS_DIR_ = f'{PROJ_DIR}/datasets/AFHQ_images_raw/afhq/train/dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4739\n"
     ]
    }
   ],
   "source": [
    "raw_imgs = glob(f'{RAW_IMGS_DIR_}/*')\n",
    "print(len(raw_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4739/4739 [02:54<00:00, 27.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# for x in tqdm(raw_imgs):\n",
    "#     DeepFAMS.preprocessing.resize_imgs(x, (256, 256), RESIZED_IMGS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw: 4739, Resized: 4739\n"
     ]
    }
   ],
   "source": [
    "print(f'Raw: {len(raw_imgs)}, Resized: {len(glob(f\"{RESIZED_IMGS_DIR}/*\"))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from \"/work/chaselab/malyetama/ADA_Project/datasets/AFHQ-DOG_resized\"\n",
      "Creating dataset \"/work/chaselab/malyetama/ADA_Project/datasets/AFHQ-DOG_custom\"\n",
      "Added 4739 images.                      \n"
     ]
    }
   ],
   "source": [
    "# DeepFAMS.preprocessing.tf_record_exporter(tfrecord_dir=DATA_CUSTOM_DIR, image_dir=RESIZED_IMGS_DIR, shuffle=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training options:\n",
      "\n",
      "{\n",
      "\n",
      "  \"G_args\": {\n",
      "\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "\n",
      "    \"fmap_base\": 8192,\n",
      "\n",
      "    \"fmap_max\": 512,\n",
      "\n",
      "    \"mapping_layers\": 2,\n",
      "\n",
      "    \"num_fp16_res\": 4,\n",
      "\n",
      "    \"conv_clamp\": 256\n",
      "\n",
      "  },\n",
      "\n",
      "  \"D_args\": {\n",
      "\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "\n",
      "    \"mbstd_group_size\": 4,\n",
      "\n",
      "    \"fmap_base\": 8192,\n",
      "\n",
      "    \"fmap_max\": 512,\n",
      "\n",
      "    \"num_fp16_res\": 4,\n",
      "\n",
      "    \"conv_clamp\": 256\n",
      "\n",
      "  },\n",
      "\n",
      "  \"G_opt_args\": {\n",
      "\n",
      "    \"beta1\": 0.0,\n",
      "\n",
      "    \"beta2\": 0.99,\n",
      "\n",
      "    \"learning_rate\": 0.0025\n",
      "\n",
      "  },\n",
      "\n",
      "  \"D_opt_args\": {\n",
      "\n",
      "    \"beta1\": 0.0,\n",
      "\n",
      "    \"beta2\": 0.99,\n",
      "\n",
      "    \"learning_rate\": 0.0025\n",
      "\n",
      "  },\n",
      "\n",
      "  \"loss_args\": {\n",
      "\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "\n",
      "    \"r1_gamma\": 0.4096\n",
      "\n",
      "  },\n",
      "\n",
      "  \"augment_args\": {\n",
      "\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "\n",
      "    \"tune_target\": 0.6,\n",
      "\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "\n",
      "    \"apply_args\": {\n",
      "\n",
      "      \"xflip\": 1,\n",
      "\n",
      "      \"rotate90\": 1,\n",
      "\n",
      "      \"xint\": 1,\n",
      "\n",
      "      \"scale\": 1,\n",
      "\n",
      "      \"rotate\": 1,\n",
      "\n",
      "      \"aniso\": 1,\n",
      "\n",
      "      \"xfrac\": 1,\n",
      "\n",
      "      \"brightness\": 1,\n",
      "\n",
      "      \"contrast\": 1,\n",
      "\n",
      "      \"lumaflip\": 1,\n",
      "\n",
      "      \"hue\": 1,\n",
      "\n",
      "      \"saturation\": 1\n",
      "\n",
      "    }\n",
      "\n",
      "  },\n",
      "\n",
      "  \"num_gpus\": 2,\n",
      "\n",
      "  \"image_snapshot_ticks\": 1,\n",
      "\n",
      "  \"network_snapshot_ticks\": 1,\n",
      "\n",
      "  \"train_dataset_args\": {\n",
      "\n",
      "    \"path\": \"/work/chaselab/malyetama/ADA_Project/datasets/AFHQ-DOG_custom\",\n",
      "\n",
      "    \"max_label_size\": 0,\n",
      "\n",
      "    \"resolution\": 256,\n",
      "\n",
      "    \"mirror_augment\": false\n",
      "\n",
      "  },\n",
      "\n",
      "  \"metric_arg_list\": [\n",
      "\n",
      "    {\n",
      "\n",
      "      \"name\": \"fid50k_full\",\n",
      "\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "\n",
      "      \"max_reals\": null,\n",
      "\n",
      "      \"num_fakes\": 50000,\n",
      "\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "\n",
      "      \"force_dataset_args\": {\n",
      "\n",
      "        \"shuffle\": false,\n",
      "\n",
      "        \"max_images\": null,\n",
      "\n",
      "        \"repeat\": false,\n",
      "\n",
      "        \"mirror_augment\": false\n",
      "\n",
      "      }\n",
      "\n",
      "    }\n",
      "\n",
      "  ],\n",
      "\n",
      "  \"metric_dataset_args\": {\n",
      "\n",
      "    \"path\": \"/work/chaselab/malyetama/ADA_Project/datasets/AFHQ-DOG_custom\",\n",
      "\n",
      "    \"max_label_size\": 0,\n",
      "\n",
      "    \"resolution\": 256,\n",
      "\n",
      "    \"mirror_augment\": false\n",
      "\n",
      "  },\n",
      "\n",
      "  \"total_kimg\": 1,\n",
      "\n",
      "  \"minibatch_size\": 32,\n",
      "\n",
      "  \"minibatch_gpu\": 16,\n",
      "\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "\n",
      "  \"G_smoothing_rampup\": 0.05,\n",
      "\n",
      "  \"run_dir\": \"/work/chaselab/malyetama/ADA_Project/training_runs/AFHQ-DOG_training-runs/00000-AFHQ-DOG_custom-auto2-kimg1\"\n",
      "\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "Output directory:  /work/chaselab/malyetama/ADA_Project/training_runs/AFHQ-DOG_training-runs/00000-AFHQ-DOG_custom-auto2-kimg1\n",
      "\n",
      "Training data:     /work/chaselab/malyetama/ADA_Project/datasets/AFHQ-DOG_custom\n",
      "\n",
      "Training length:   1 kimg\n",
      "\n",
      "Resolution:        256\n",
      "\n",
      "Number of GPUs:    2\n",
      "\n",
      "\n",
      "\n",
      "Creating output directory...\n",
      "\n",
      "Loading training set...\n",
      "\n",
      "Image shape: [3, 256, 256]\n",
      "\n",
      "Label shape: [0]\n",
      "\n",
      "\n",
      "\n",
      "Constructing networks...\n",
      "\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Loading... Done.\n",
      "\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Loading... Done.\n",
      "\n",
      "\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "\n",
      "---                           ---       ---                 ---             \n",
      "\n",
      "latents_in                    -         (?, 512)            -               \n",
      "\n",
      "labels_in                     -         (?, 0)              -               \n",
      "\n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "\n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "\n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "\n",
      "G_mapping/Broadcast           -         (?, 14, 512)        -               \n",
      "\n",
      "dlatent_avg                   -         (512,)              -               \n",
      "\n",
      "Truncation/Lerp               -         (?, 14, 512)        -               \n",
      "\n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "\n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "\n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "\n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "\n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "\n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "\n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "\n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "\n",
      "G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "\n",
      "G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "\n",
      "G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "\n",
      "G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "\n",
      "G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "\n",
      "G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "\n",
      "G_synthesis/256x256/Conv0_up  139457    (?, 64, 256, 256)   (3, 3, 128, 64) \n",
      "\n",
      "G_synthesis/256x256/Conv1     69761     (?, 64, 256, 256)   (3, 3, 64, 64)  \n",
      "\n",
      "G_synthesis/256x256/Upsample  -         (?, 3, 256, 256)    -               \n",
      "\n",
      "G_synthesis/256x256/ToRGB     33027     (?, 3, 256, 256)    (1, 1, 64, 3)   \n",
      "\n",
      "---                           ---       ---                 ---             \n",
      "\n",
      "Total                         23191522                                      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "\n",
      "---                  ---       ---                 ---             \n",
      "\n",
      "images_in            -         (?, 3, 256, 256)    -               \n",
      "\n",
      "labels_in            -         (?, 0)              -               \n",
      "\n",
      "256x256/FromRGB      256       (?, 64, 256, 256)   (1, 1, 3, 64)   \n",
      "\n",
      "256x256/Conv0        36928     (?, 64, 256, 256)   (3, 3, 64, 64)  \n",
      "\n",
      "256x256/Conv1_down   73856     (?, 128, 128, 128)  (3, 3, 64, 128) \n",
      "\n",
      "256x256/Skip         8192      (?, 128, 128, 128)  (1, 1, 64, 128) \n",
      "\n",
      "128x128/Conv0        147584    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "\n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "\n",
      "128x128/Skip         32768     (?, 256, 64, 64)    (1, 1, 128, 256)\n",
      "\n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "\n",
      "64x64/Skip           131072    (?, 512, 32, 32)    (1, 1, 256, 512)\n",
      "\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "\n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "\n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "\n",
      "---                  ---       ---                 ---             \n",
      "\n",
      "Total                24001089                                      \n",
      "\n",
      "\n",
      "\n",
      "Exporting sample images...\n",
      "\n",
      "Replicating networks across 2 GPUs...\n",
      "\n",
      "Initializing augmentations...\n",
      "\n",
      "Setting up optimizers...\n",
      "\n",
      "Constructing training graph...\n",
      "\n",
      "Finalizing training ops...\n",
      "\n",
      "Initializing metrics...\n",
      "\n",
      "Training for 1 kimg...\n",
      "\n",
      "\n",
      "\n",
      "tick 0     kimg 0.1      time 2m 49s       sec/tick 23.1    sec/kimg 180.45  maintenance 146.2  gpumem 7.1   augment 0.000\n",
      "\n",
      "Evaluating metrics...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network-snapshot-000000        time 2m 24s       fid50k_full 308.9665\n",
      "\n",
      "tick 1     kimg 1.0      time 5m 53s       sec/tick 13.1    sec/kimg 14.64   maintenance 170.7  gpumem 7.1   augment 0.001\n",
      "\n",
      "Evaluating metrics...\n",
      "\n",
      "network-snapshot-000001        time 2m 25s       fid50k_full 348.3302\n",
      "\n",
      "\n",
      "\n",
      "Exiting...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DeepFAMS.utils.executePopen(f'''#!/bin/bash\n",
    "module load anaconda\n",
    "module load compiler/gcc/4.7\n",
    "module load cuda\n",
    "$WORK/.conda/envs/ada-env/bin/python $WORK/ADA_Project/StyleGAN2-ada/train.py \\\n",
    "--outdir={TRAIN_RUNS_DIR} \\\n",
    "--gpus=2 \\\n",
    "--data={DATA_CUSTOM_DIR} \\\n",
    "--snap=1 \\\n",
    "--kimg=1''', PROJ_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/chaselab/malyetama/ADA_Project/training_runs/AFHQ-DOG_training-runs/00000-AFHQ-DOG_custom-auto2-kimg1/network-snapshot-000001.pkl\n"
     ]
    }
   ],
   "source": [
    "for num in range(-1, -10, -1):\n",
    "    files = DeepFAMS.utils.last_snap(num, TRAIN_RUNS_DIR)\n",
    "    if files != []:\n",
    "        break\n",
    "\n",
    "latest_snap = sorted(files)[-1]\n",
    "print(latest_snap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_desc, training_options = DeepFAMS.setup_training_options(\n",
    "    gpus       = 2,\n",
    "    snap       = 10,\n",
    "    data       = DATA_CUSTOM_DIR,\n",
    "    resume     = latest_snap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeepFAMS.utils.execute('nvidia-smi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeepFAMS.RunTraining(outdir=TRAIN_RUNS_DIR, seed=1000,\n",
    "             dry_run=True, run_desc=run_desc, training_options=training_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "DeepFAMS.RunTraining(outdir=TRAIN_RUNS_DIR, seed=1000,\n",
    "             dry_run=False, run_desc=run_desc, training_options=training_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ada-env)",
   "language": "python",
   "name": "ada-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
