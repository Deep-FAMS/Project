{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lustre/work/chaselab/malyetama\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "WORK = os.environ[\"WORK\"]\n",
    "%cd $WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from PIL import Image as Img\n",
    "import os\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import imageio\n",
    "from pygifsicle import optimize\n",
    "from IPython.display import Markdown, display, Image\n",
    "import dotenv\n",
    "import base64\n",
    "import requests\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "\n",
    "def create_fakes_gif(\n",
    "    DATASET_NAME,\n",
    "    subset=None,\n",
    "    output_dir=None,\n",
    "    ftype='gif',\n",
    "    display_output=False,\n",
    "    verbose=False,\n",
    "    shift={\n",
    "        'shift_r': 0,\n",
    "        'shift_b': 0\n",
    "    }\n",
    "):\n",
    "    \n",
    "    def process(i):\n",
    "        im = Img.open(i)\n",
    "        if DATASET_NAME == 'metfaces':\n",
    "            left, top, right, bottom = 0, 0, (256 * 4) * 2, (256 * 4) * 2\n",
    "        else:\n",
    "            left, top, right, bottom = 1 * shift['shift_r'], 1 * shift[\n",
    "                'shift_b'], (256 * 4) + shift['shift_r'], (256 * 4) + shift['shift_b']\n",
    "        im_cropped = im.crop((left, top, right, bottom))\n",
    "        return im_cropped.save(f'{history}/{Path(i).stem}.png')\n",
    "    \n",
    "    def upload_img(image, token):\n",
    "        with open(image, \"rb\") as file:\n",
    "            url = \"https://api.imgbb.com/1/upload\"\n",
    "            parameters = {\n",
    "                \"key\": token,\n",
    "                \"image\": base64.b64encode(file.read()),\n",
    "            }\n",
    "            res = requests.post(url, parameters)\n",
    "            link = res.json()\n",
    "            url = link['data']['url']\n",
    "            return url\n",
    "\n",
    "    WORK = os.environ[\"WORK\"]\n",
    "    PROJ_DIR = f'{WORK}/ADA_Project'\n",
    "    \n",
    "    dotenv.load_dotenv(f'{PROJ_DIR}/.env')\n",
    "    token = os.getenv('TOKEN')\n",
    "    \n",
    "    history = f'{PROJ_DIR}/datasets/{DATASET_NAME}_history'\n",
    "    try:\n",
    "        shutil.rmtree(history)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    TRfolders = f'{PROJ_DIR}/training_runs/'\n",
    "    TRfolders_ = glob(f'{PROJ_DIR}/training_runs/*')\n",
    "    datasets = [\n",
    "        x.replace(TRfolders, '').replace('_training-runs', '')\n",
    "        for x in TRfolders_\n",
    "    ]\n",
    "    ds_rename = lambda before, after: [after if x == before else x for x in datasets]\n",
    "    datasets = ds_rename('AFHQ', 'AFHQ-CAT')\n",
    "    \n",
    "#     if verbose:\n",
    "#         print(f'Available datasets:\\n {datasets}')\n",
    "\n",
    "    d = {}\n",
    "    \n",
    "    with open(f'{PROJ_DIR}/FID_of_best_snapshots.json') as jf:\n",
    "        jd = json.load(jf)\n",
    "        best = 'fakes' + jd[DATASET_NAME]['snapshot'].replace('network-snapshot-', '')\n",
    "\n",
    "    for folder, dataset in zip(TRfolders_, datasets):\n",
    "        files = sorted(glob(folder + \"/**/*\"))\n",
    "        fakes = [x for x in files if 'fakes' in x]\n",
    "        if fakes == []:\n",
    "            continue\n",
    "        d[dataset] = {}\n",
    "        d[dataset]['files'] = fakes\n",
    "        \n",
    "    __fakes = d[DATASET_NAME]['files']\n",
    "    if (len(__fakes) % 2) != 0:\n",
    "        __fakes = __fakes[:-1]\n",
    "        \n",
    "    best_fake = f'{Path(__fakes[-1]).parent}/{best}{Path(__fakes[-1]).suffix}'\n",
    "    __fakes = __fakes[::subset] + [best_fake]\n",
    "        \n",
    "        \n",
    "    Path(history).mkdir(exist_ok=True)\n",
    "    \n",
    "    n_jobs = multiprocessing.cpu_count() - 1\n",
    "\n",
    "    _ = Parallel(n_jobs=n_jobs)(delayed(process)(i)\n",
    "                                     for i in tqdm(__fakes))\n",
    "\n",
    "    history_imgs = sorted([x for x in glob(f'{history}/*.png')])\n",
    "    history_imgs = [history_imgs[-1]] + [x for x in history_imgs if 'init' not in x]\n",
    "    \n",
    "    \n",
    "#     if subset is not None and verbose:\n",
    "#         print(f'Subset size: {len(history_imgs)} image')\n",
    "\n",
    "    if output_dir is None:\n",
    "        output_dir = Path.cwd()\n",
    "        anim_file = f'{output_dir}/{DATASET_NAME}.{ftype}'\n",
    "    anim_file = f'{DATASET_NAME}.{ftype}'\n",
    "    \n",
    "    with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "        for filename in tqdm(history_imgs):\n",
    "            image = imageio.imread(filename)\n",
    "            writer.append_data(image)\n",
    "            if str(Path(filename).stem) == best:\n",
    "                break\n",
    "        best_fake = f'{Path(history_imgs[-1]).parent}/{best}{Path(history_imgs[-1]).suffix}'\n",
    "        best_fake = imageio.imread(best_fake)\n",
    "        for _ in range(20):\n",
    "            writer.append_data(best_fake)\n",
    "    \n",
    "    file_size = lambda file: Path(file).stat().st_size / 1e+6\n",
    "    if verbose:\n",
    "        if ftype == 'mp4':\n",
    "            print(f'file size: {file_size(anim_file):.2f} MB')\n",
    "        else:\n",
    "            print(f'file size before optimization: {file_size(anim_file):.2f} MB')\n",
    "    \n",
    "    if ftype == 'gif':\n",
    "        optimize(source=anim_file, destination=anim_file)\n",
    "            \n",
    "        if verbose:\n",
    "            print(f'          after optimization: {file_size(anim_file):.2f} MB')\n",
    "    \n",
    "    if display_output is True:\n",
    "        if ftype == 'gif':\n",
    "            print('Loading...')\n",
    "            img_url = upload_img(anim_file, token)\n",
    "            print(f'{ftype} url ==> {img_url}')\n",
    "            display(Markdown(f'![]({img_url})'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available datasets:\n",
    " ['AFHQ-WILD', 'AFHQ-CAT', 'StyleGAN2_FFHQ_30K', 'metfaces', 'POKEMON', 'StanfordDogs',\n",
    "  'StyleGAN2_AFHQ-DOG', 'cars196', 'AFHQ-DOG', 'FFHQ_5K', 'FFHQ_2K', 'ANIME-FACES',\n",
    "  'conditional_CIFAR-10', 'StyleGAN2_FFHQ_5K', 'StyleGAN2_WILD-AFHQ',\n",
    "  'unconditional_CIFAR-10', '102flowers', 'StyleGAN2_FFHQ', 'FFHQ_30K', 'FFHQ', 'StyleGAN2_FFHQ_2K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 209.17it/s]A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 3/63 [00:00<00:02, 20.44it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset size: 63 image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 10%|▉         | 6/63 [00:00<00:02, 21.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 9/63 [00:00<00:02, 21.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 12/63 [00:00<00:02, 21.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 15/63 [00:00<00:02, 21.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▊       | 18/63 [00:00<00:02, 21.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 21/63 [00:00<00:01, 21.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 24/63 [00:01<00:01, 21.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 27/63 [00:01<00:01, 21.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 30/63 [00:01<00:01, 21.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 33/63 [00:01<00:01, 21.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 36/63 [00:01<00:01, 21.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 39/63 [00:01<00:01, 21.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 42/63 [00:01<00:00, 21.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████▏  | 45/63 [00:02<00:00, 21.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 48/63 [00:02<00:00, 21.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 51/63 [00:02<00:00, 21.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 54/63 [00:02<00:00, 20.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 57/63 [00:02<00:00, 20.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 60/63 [00:02<00:00, 20.78it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file size: 10.30 MB\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = 'AFHQ-WILD'\n",
    "\n",
    "create_fakes_gif(\n",
    "    DATASET_NAME=DATASET_NAME,\n",
    "    display_output=True,\n",
    "    verbose=True,\n",
    "    subset=10,\n",
    "    ftype='mp4',\n",
    "    shift={\n",
    "        'shift_r': 256 * 0,\n",
    "        'shift_b': 256 * 4\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.3.1 Copyright (c) 2000-2020 the FFmpeg developers\n",
      "  built with gcc 7.5.0 (crosstool-NG 1.24.0.131_87df0e6_dirty)\n",
      "  configuration: --prefix=/work/chaselab/malyetama/.conda/envs/ada-env --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1596712246804/_build_env/bin/x86_64-conda-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-gnutls --enable-gpl --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-libx264 --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame\n",
      "  libavutil      56. 51.100 / 56. 51.100\n",
      "  libavcodec     58. 91.100 / 58. 91.100\n",
      "  libavformat    58. 45.100 / 58. 45.100\n",
      "  libavdevice    58. 10.100 / 58. 10.100\n",
      "  libavfilter     7. 85.100 /  7. 85.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  7.100 /  5.  7.100\n",
      "  libswresample   3.  7.100 /  3.  7.100\n",
      "  libpostproc    55.  7.100 / 55.  7.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'AFHQ-WILD.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:08.10, start: 0.000000, bitrate: 10173 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1024x1024, 10171 kb/s, 10 fps, 10 tbr, 10240 tbn, 20 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> gif (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, gif, to 'AFHQ-WILD.gif':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.45.100\n",
      "    Stream #0:0(und): Video: gif, pal8, 512x512, q=2-31, 200 kb/s, 10 fps, 100 tbn, 10 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      encoder         : Lavc58.91.100 gif\n",
      "\u001b[1;32m[Parsed_palettegen_3 @ 0x55fe0407a480] \u001b[0m255(+1) colors generated out of 1384649 colors; ratio=0.000184\n",
      "frame=   81 fps=9.8 q=-0.0 Lsize=   14738kB time=00:00:08.01 bitrate=15073.3kbits/s speed=0.966x    \n",
      "video:14738kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000133%\n"
     ]
    }
   ],
   "source": [
    "_in = DATASET_NAME + '.mp4'\n",
    "_out = DATASET_NAME + '.gif'\n",
    "! /work/chaselab/malyetama/.conda/envs/ada-env/bin/ffmpeg -i $_in -vf \\\n",
    "    \"fps=10,scale=512:-1:flags=lanczos,split[s0][s1];[s0]palettegen[p];[s1][p]paletteuse\" \\\n",
    "    -loop 0 $_out -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_img(image, token):\n",
    "    with open(image, \"rb\") as file:\n",
    "        url = \"https://api.imgbb.com/1/upload\"\n",
    "        parameters = {\n",
    "            \"key\": token,\n",
    "            \"image\": base64.b64encode(file.read()),\n",
    "        }\n",
    "        res = requests.post(url, parameters)\n",
    "        link = res.json()\n",
    "        url = link['data']['url']\n",
    "        return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://i.ibb.co/hHSVh77/fa5d8d47e524.gif\n"
     ]
    }
   ],
   "source": [
    "link = upload_img(_out, os.getenv('TOKEN'))\n",
    "print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(Image(_out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ada-env)",
   "language": "python",
   "name": "ada-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
